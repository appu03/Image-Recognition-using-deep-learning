{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings; \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Adding Convolution layer\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer for more accuracy\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flattening layer\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Full connection (Hidden layer)\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_img = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_img.flow_from_directory(\"D:\\\\DEEP_Learning(UDEMY)\\\\CONVOLUTIONAL_NUERAL_NETWORK\\\\dataset\\\\training_set\",\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1991 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = test_img.flow_from_directory(\"D:\\\\DEEP_Learning(UDEMY)\\\\CONVOLUTIONAL_NUERAL_NETWORK\\\\dataset\\\\test_set\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apurv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 627s 3s/step - loss: 0.6845 - acc: 0.5545 - val_loss: 0.6335 - val_acc: 0.6455\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 391s 2s/step - loss: 0.6117 - acc: 0.6661 - val_loss: 0.5875 - val_acc: 0.6878\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 367s 1s/step - loss: 0.5745 - acc: 0.6962 - val_loss: 0.5390 - val_acc: 0.7434\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 365s 1s/step - loss: 0.5450 - acc: 0.7230 - val_loss: 0.5470 - val_acc: 0.7266\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 396s 2s/step - loss: 0.5189 - acc: 0.7429 - val_loss: 0.4832 - val_acc: 0.7734\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 388s 2s/step - loss: 0.4915 - acc: 0.7591 - val_loss: 0.4731 - val_acc: 0.7777\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 369s 1s/step - loss: 0.4792 - acc: 0.7740 - val_loss: 0.5893 - val_acc: 0.7205\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 367s 1s/step - loss: 0.4598 - acc: 0.7775 - val_loss: 0.4790 - val_acc: 0.7699\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 365s 1s/step - loss: 0.4492 - acc: 0.7886 - val_loss: 0.4660 - val_acc: 0.7740\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 407s 2s/step - loss: 0.4437 - acc: 0.7909 - val_loss: 0.4889 - val_acc: 0.7679\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 393s 2s/step - loss: 0.4279 - acc: 0.8013 - val_loss: 0.4617 - val_acc: 0.7821\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 366s 1s/step - loss: 0.4131 - acc: 0.8098 - val_loss: 0.4819 - val_acc: 0.7740\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 367s 1s/step - loss: 0.4134 - acc: 0.8092 - val_loss: 0.4713 - val_acc: 0.7863\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 377s 2s/step - loss: 0.4013 - acc: 0.8127 - val_loss: 0.4494 - val_acc: 0.7930\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 372s 1s/step - loss: 0.3864 - acc: 0.8247 - val_loss: 0.4381 - val_acc: 0.8031\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 366s 1s/step - loss: 0.3819 - acc: 0.8261 - val_loss: 0.4591 - val_acc: 0.7972\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 368s 1s/step - loss: 0.3712 - acc: 0.8321 - val_loss: 0.4847 - val_acc: 0.7774\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 390s 2s/step - loss: 0.3677 - acc: 0.8322 - val_loss: 0.4301 - val_acc: 0.8038\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 403s 2s/step - loss: 0.3579 - acc: 0.8392 - val_loss: 0.4655 - val_acc: 0.7853\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 454s 2s/step - loss: 0.3476 - acc: 0.8471 - val_loss: 0.4532 - val_acc: 0.7995\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 455s 2s/step - loss: 0.3351 - acc: 0.8521 - val_loss: 0.4544 - val_acc: 0.7884\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 455s 2s/step - loss: 0.3212 - acc: 0.8604 - val_loss: 0.5409 - val_acc: 0.7738\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 887s 4s/step - loss: 0.3351 - acc: 0.8566 - val_loss: 0.4623 - val_acc: 0.8135\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 473s 2s/step - loss: 0.3109 - acc: 0.8638 - val_loss: 0.4636 - val_acc: 0.8032\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 460s 2s/step - loss: 0.3106 - acc: 0.8644 - val_loss: 0.4548 - val_acc: 0.8116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9f7763d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train_data,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_data,\n",
    "                         nb_val_samples = 1991)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the test accuracy comes out to be 81% and train accuracy comes out to be 86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(\"D:\\img_1.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "train_data.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(\"D:\\img_2.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "train_data.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully predicted the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
